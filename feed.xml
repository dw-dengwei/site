<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en, cn"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://dw-dengwei.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://dw-dengwei.github.io/" rel="alternate" type="text/html" hreflang="en, cn"/><updated>2024-01-10T12:03:34+00:00</updated><id>https://dw-dengwei.github.io/feed.xml</id><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Generative Models - Editing</title><link href="https://dw-dengwei.github.io/blog/Diffusion-Model-Editing/" rel="alternate" type="text/html" title="Generative Models - Editing"/><published>2023-12-14T00:00:00+00:00</published><updated>2023-12-14T00:00:00+00:00</updated><id>https://dw-dengwei.github.io/blog/Diffusion%20Model%20-%20Editing</id><content type="html" xml:base="https://dw-dengwei.github.io/blog/Diffusion-Model-Editing/"><![CDATA[]]></content><author><name></name></author><category term="generative-models"/><summary type="html"><![CDATA[Image editing using DPMs]]></summary></entry><entry><title type="html">Mathematics</title><link href="https://dw-dengwei.github.io/blog/Mathematics/" rel="alternate" type="text/html" title="Mathematics"/><published>2023-12-14T00:00:00+00:00</published><updated>2023-12-14T00:00:00+00:00</updated><id>https://dw-dengwei.github.io/blog/Mathematics</id><content type="html" xml:base="https://dw-dengwei.github.io/blog/Mathematics/"><![CDATA[<h1 id="得分匹配">得分匹配</h1> <p>目标:</p> \[\begin{align} J(\theta) &amp;= \mathbb{E}_{x\sim p(x)} \left[ \Vert s(x;\theta) - \nabla_x\log p(x) \Vert^2 \right] \\ &amp;= \mathbb{E}_{x\sim p(x)} \left[ \Vert s(x;\theta)\Vert^2 + \underbrace{\Vert \nabla_x\log p(x)\Vert^2}_{\text{constant}} - 2s(x;\theta)^T\nabla_x\log p(x) \right ] \\ &amp;= \mathbb{E}_{x\sim p(x)} \left[ \Vert s(x;\theta) \Vert^2 \right] - 2\int_{x\in\mathbb{R}^n} p(x)\sum_i s_i(x;\theta)\frac{\partial\log p(x)}{\partial x_i} \mathrm{d}x + \text{constant} \\ &amp;= \mathbb{E}_{x\sim p(x)} \left[ \Vert s(x;\theta) \Vert^2 \right] - 2\sum_i\int_{x\in\mathbb{R}^n}s_i(x;\theta)\frac{\partial p(x)}{\partial x_i} \mathrm{d}x + \text{constant} \\ &amp;= \mathbb{E}_{x\sim p(x)} \left[ \Vert s(x;\theta) \Vert^2 \right] -2\sum_i\underbrace{\iint\cdots\int}_{n}s_i(x;\theta)\frac{\partial p(x)}{\partial x_i}\mathrm{d}x_1\cdots\mathrm{d}x_n + \text{constant} \\ &amp;= \mathbb{E}_{x\sim p(x)} \left[ \Vert s(x;\theta) \Vert^2 \right] -2\sum_i\iint\cdots\int_{x_i\in\mathbb{R}}s_i(x;\theta)\frac{\partial p(x)}{\partial x_i} \mathrm{d}x_i \iint\cdots\int\frac{\mathrm{d}x_1\cdots\mathrm{d}x_n}{\mathrm{d}x_i} + \text{constant} \\ &amp;= \mathbb{E}_{x\sim p(x)} \left[ \Vert s(x;\theta) \Vert^2 \right] -\\ &amp;2\sum_i\iint\cdots\int_{x_i\in\mathbb{R}} \left( \underbrace{s_i(x;\theta) p(x)\bigg|_{x_i\to-\infty}^{x_i\to+\infty}}_{\lim_{x_i\to\infty} s_i(x;\theta)p(x)\to 0} -\frac{\partial s_i(x;\theta)}{\partial x_i}p(x) \right)\mathrm{d}x_i \iint\cdots\int\frac{\mathrm{d}x_1\cdots\mathrm{d}x_n}{\mathrm{d}x_i} + \text{constant} \\ &amp;= \mathbb{E}_{x\sim p(x)} \left[ \Vert s(x;\theta) \Vert^2 \right] +2\sum_i\iint\cdots\int_{x_i\in\mathbb{R}} \left( \frac{\partial s_i(x;\theta)}{\partial x_i}p(x) \right)\mathrm{d}x_i \iint\cdots\int\frac{\mathrm{d}x_1\cdots\mathrm{d}x_n}{\mathrm{d}x_i} + \text{constant} \\ &amp;= \mathbb{E}_{x\sim p(x)} \left[ \Vert s(x;\theta) \Vert^2 \right] +2\sum_i\underbrace{\iint\cdots\int}_{n} \frac{\partial s_i(x;\theta)}{\partial x_i}p(x)\mathrm{d}x_1\cdots\mathrm{d}x_n + \text{constant}\\ &amp;= \mathbb{E}_{x\sim p(x)} \left[ \Vert s(x;\theta) \Vert^2 \right] +2\sum_i\int_{x\in\mathbb{R}^n} \frac{\partial s_i(x;\theta)}{\partial x_i}p(x)\mathrm{d}x + \text{constant}\\ &amp;= \mathbb{E}_{x\sim p(x)} \left[ \Vert s(x;\theta) \Vert^2 \right] +2\int_{x\in\mathbb{R}^n}\sum_i \frac{\partial s_i(x;\theta)}{\partial x_i}p(x)\mathrm{d}x + \text{constant}\\ &amp;= \mathbb{E}_{x\sim p(x)} \left[ \Vert s(x;\theta) \Vert^2 \right] +2\int_{x\in\mathbb{R}^n} \mathrm{tr}(\nabla_x s(x;\theta)) p(x)\mathrm{d}x + \text{constant}\\ &amp;= \mathbb{E}_{x\sim p(x)} \left[ \Vert s(x;\theta) \Vert^2 \right] +2\mathbb{E}_{x\sim p(x)} \left[ \mathrm{tr}(\nabla_x s(x;\theta)) \right] + \text{constant}\\ &amp;= \mathbb{E}_{x\sim p(x)} \left[ \Vert s(x;\theta) \Vert^2 +2\mathrm{tr}(\nabla_x s(x;\theta)) \right] + \text{constant} \end{align}\] <h1 id="期望符号的下标">期望符号的下标</h1> <p>期望符号的下标有两种含义：</p> <ol> <li>下标符号中的变量作为条件：\(\mathbb{E}_{x}\left[y\right]=\mathbb{E}\left[y\vert x\right]\)</li> <li>下标符号中的变量用作计算平均：\(\mathbb{E}_{x}\left[y\right]=\int yp(x)\mathrm{d}x\)</li> </ol> <h1 id="kl散度和交叉熵相对logits的梯度">KL散度和交叉熵相对Logits的梯度</h1> <p>\(\frac {\partial \mathcal{L}_{\mathrm KD}} {\partial z_i} = \tau \left(\hat{y}^s_{i,\tau} - \hat{y}^t_{i,\tau}\right)\)</p> \[\frac {\partial \mathcal{L}_{\mathrm CE}} {\partial z_i} = \hat{y}^s_{i,1} - \hat{y}_{i}\]]]></content><author><name>Wei Deng</name></author><category term="generative-models"/><summary type="html"><![CDATA[Mathematic list]]></summary></entry><entry><title type="html">Figures</title><link href="https://dw-dengwei.github.io/blog/Figures/" rel="alternate" type="text/html" title="Figures"/><published>2023-12-14T00:00:00+00:00</published><updated>2023-12-14T00:00:00+00:00</updated><id>https://dw-dengwei.github.io/blog/Figures</id><content type="html" xml:base="https://dw-dengwei.github.io/blog/Figures/"><![CDATA[<h1 id="stop-gradients">Stop gradients</h1> <p>在前向图上面标记，表示在反向过程中停止梯度的传递</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Pasted%20image%2020231217175013-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Pasted%20image%2020231217175013-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Pasted%20image%2020231217175013-1400.webp"/> <img src="/assets/img/Pasted%20image%2020231217175013.png" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure>]]></content><author><name>Wei Deng</name></author><category term="generative-models"/><summary type="html"><![CDATA[Figure list]]></summary></entry><entry><title type="html">Diffusion Models - DDIM</title><link href="https://dw-dengwei.github.io/blog/Diffusion-Models-DDIM/" rel="alternate" type="text/html" title="Diffusion Models - DDIM"/><published>2023-10-06T00:00:00+00:00</published><updated>2023-10-06T00:00:00+00:00</updated><id>https://dw-dengwei.github.io/blog/Diffusion%20Models%20-%20DDIM</id><content type="html" xml:base="https://dw-dengwei.github.io/blog/Diffusion-Models-DDIM/"><![CDATA[<h1 id="review-of-ddpm">Review of DDPM</h1> <ol> <li> <p>Diffusion阶段<br/> \(\begin{align} q(x_t\vert x_0)&amp;=\boxed{\mathcal{N}(x_t;\sqrt{\bar{\alpha}_t}x_0,(1-\bar{\alpha}_t)I)}\\ &amp;=\sqrt{\bar{\alpha}_t}x_0+\sqrt{1-\bar{\alpha}_t}\epsilon \text{ ,where } \epsilon\sim\mathcal{N}(0,I) \end{align}\)</p> </li> <li> <p>Reverse阶段<br/> 使用贝叶斯公式<br/> \(\begin{align} q(x_{t-1}\vert x_t)&amp;=\frac{q(x_t\vert x_{t-1})q(x_{t-1})}{q(x_t)} \end{align}\)<br/> 发现公式中\(q(x_{t-1})\)和\(q(x_t)\)不好求，根据DDPM的马尔科夫假设：<br/> \(\begin{align} q(x_{t-1}\vert x_t)&amp;=q(x_{t-1}\vert x_t,x_0)\\ &amp;=\frac{q(x_t\vert x_{t-1},x_0)q(x_{t-1}\vert x_0)}{q(x_t\vert x_0)}\\ &amp;=\frac{q(x_t\vert x_{t-1})q(x_{t-1}\vert x_0)}{q(x_t\vert x_0)}\\ &amp;=\boxed{\mathcal{N}(x_{t-1};\mu(x_t;\theta),\sigma_t^2I)} \end{align}\)<br/> 其中，\(\sigma_t\)可以用超参数表示，\(\mu(x_t;\theta)\)是一个神经网络，用于预测均值：<br/> \(\begin{align} \mu(x_t;\theta)&amp;=\frac{\sqrt{\alpha_t}(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_t}x_t+ \frac{\sqrt{\bar{x}_{t-1}}\beta_t}{1-\bar{\alpha}_t}x_0\\ &amp;=\boxed{\frac{\sqrt{\alpha_t}(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_t}x_t+ \frac{\sqrt{\bar{x}_{t-1}}\beta_t}{1-\bar{\alpha}_t}\hat{x}_{0\vert t}}\\ \sigma_t^2&amp;=\boxed{\frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_t}\cdot\beta_t} \end{align}\)</p> <h1 id="from-ddpm-to-ddim">From DDPM to DDIM</h1> <p>同样是对分布\(q(x_{t-1}\vert x_t,x_0)\)进行求解：<br/> \(\begin{align} q(x_{t-1}\vert x_t,x_0) &amp;=\sqrt{\bar{\alpha}_{t-1}}x_0+\sqrt{1-\bar{\alpha}_{t-1}}\epsilon\\ &amp;=\sqrt{\bar{\alpha}_{t-1}} \hat{x}_{0\vert t} +\sqrt{1-\bar{\alpha}_{t-1}}\epsilon \text{ ,where }\epsilon\sim\mathcal{N}(0,I) \end{align}\)<br/> 在上式中，\(\epsilon\)是一个噪声，虽然可以重新从高斯分布采样，但是也可以使用噪声估计网络估计出来的结果\(\epsilon_\theta(x_t,t)\)：<br/> \(\begin{align} q(x_{t-1}\vert x_t,x_0) &amp;=\sqrt{\bar{\alpha}_{t-1}}x_0+\sqrt{1-\bar{\alpha}_{t-1}}\epsilon\\ &amp;=\sqrt{\bar{\alpha}_{t-1}} \hat{x}_{0\vert t} +\sqrt{1-\bar{\alpha}_{t-1}}\epsilon \text{ ,where }\epsilon\sim\mathcal{N}(0,I)\\ &amp;=\sqrt{\bar{\alpha}_{t-1}} \hat{x}_{0\vert t} +\sqrt{1-\bar{\alpha}_{t-1}}\epsilon_\theta(x_t,t)\\ \end{align}\)<br/> 甚至可以同时考虑\(\epsilon\)和\(\epsilon_\theta(x_t,t)\)：<br/> \(\begin{align} q(x_{t-1}\vert x_t,x_0) &amp;=\sqrt{\bar{\alpha}_{t-1}}x_0+\sqrt{1-\bar{\alpha}_{t-1}}\epsilon\\ &amp;=\sqrt{\bar{\alpha}_{t-1}} \hat{x}_{0\vert t} +\sqrt{1-\bar{\alpha}_{t-1}}\epsilon \text{ ,where }\epsilon\sim\mathcal{N}(0,I)\\ &amp;=\sqrt{\bar{\alpha}_{t-1}} \hat{x}_{0\vert t} +\sqrt{1-\bar{\alpha}_{t-1}}\epsilon_\theta(x_t,t)\\ \end{align}\)</p> <h1 id="reference">Reference</h1> </li> </ol>]]></content><author><name>Wei Deng</name></author><category term="diffusion-model"/><summary type="html"><![CDATA[introduction about DDIM]]></summary></entry><entry><title type="html">Diffusion Models - DDPM</title><link href="https://dw-dengwei.github.io/blog/Diffusion-Models-DDPM/" rel="alternate" type="text/html" title="Diffusion Models - DDPM"/><published>2023-10-06T00:00:00+00:00</published><updated>2023-10-06T00:00:00+00:00</updated><id>https://dw-dengwei.github.io/blog/Diffusion%20Models%20-%20DDPM</id><content type="html" xml:base="https://dw-dengwei.github.io/blog/Diffusion-Models-DDPM/"><![CDATA[<h1 id="diffusion-process">Diffusion Process</h1> <p>前向扩散指的是将一个复杂分布转换成简单分布的过程\(\mathcal{T}:\mathbb{R}^d\mapsto\mathbb{R}^d\)，即：<br/> \(\mathbf{x}_0\sim p_\mathrm{complex}\Longrightarrow \mathcal{T}(\mathbf{x}_0)\sim p_\mathrm{prior}\)<br/> 在DDPM中，将这个过程定义为<strong>马尔可夫链</strong>，通过不断地向复杂分布中的样本\(x_0\sim p_\mathrm{complex}\)添加高斯噪声。这个加噪过程可以表示为\(q(\mathbf{x}_t\vert\mathbf{x}_{t-1})\)：<br/> \(\begin{align} q(\mathbf{x}_t \vert \mathbf{x}_{t-1}) &amp;= \mathcal{N}(\mathbf{x}_t; \sqrt{1 - \beta_t} \mathbf{x}_{t-1}, \beta_t\mathbf{I})\\ \mathbf{x}_t&amp;=\sqrt{1-\beta_t}\mathbf{x}_{t-1}+\sqrt{\beta_t}\boldsymbol\epsilon \quad \boldsymbol\epsilon\sim\mathcal{N}(\mathbf{0},\mathbf{I}) \end{align}\)<br/> 其中，\(\{\beta_t\in(0,1)\}^T_{t=1}\)，是超参数。<br/> 从\(\mathbf{x}_0\)开始，不断地应用\(q(\mathbf{x}_t\vert\mathbf{x}_{t-1})\)，经过足够大的\(T\)步加噪之后，最终得到纯噪声\(\mathbf{x}_T\)：<br/> \(\mathbf{x}_0\sim p_\mathrm{complex}\rightarrow \mathbf{x}_1\rightarrow \cdots \mathbf{x}_t\rightarrow\cdots\rightarrow \mathbf{x}_T\sim p_\mathrm{prior}\)<br/> 除了迭代地使用\(q(\mathbf{x}_t\vert\mathbf{x}_{t-1})\)外，还可以使用\(q(\mathbf{x}_t\vert\mathbf{x}_0) = \mathcal{N}(\mathbf{x}_t; \sqrt{\bar{\alpha}_t} \mathbf{x}_0, (1 - \bar{\alpha}_t)\mathbf{I})\)一步到位，证明如下（两个高斯变量的线性组合仍然是高斯变量）：<br/> \(\begin{aligned} \mathbf{x}_t &amp;= \sqrt{\alpha_t}\mathbf{x}_{t-1} + \sqrt{1 - \alpha_t}\boldsymbol{\epsilon}_{t-1} &amp;\ ;\alpha_t=1-\alpha_t\\ &amp;= \sqrt{\alpha_t \alpha_{t-1}} \mathbf{x}_{t-2} + \sqrt{1 - \alpha_t \alpha_{t-1}} \bar{\boldsymbol{\epsilon}}_{t-2} \\ &amp;= \dots \\ &amp;= \sqrt{\bar{\alpha}_t}\mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_t}\boldsymbol{\epsilon} &amp;\ ;\boldsymbol{\epsilon}\sim \mathcal{N}(\mathbf{0}, \mathbf{I}),\bar{\alpha}_t=\prod_{i=1}^t \alpha_i\ \end{aligned}\)<br/> 一般来说，超参数\(\beta_t\)的设置满足\(0&lt;\beta_1&lt;\cdots&lt;\beta_T&lt;1\)，则\(\bar{\alpha}_1 &gt; \cdots &gt; \bar{\alpha}_T\to1\)，则\(\mathbf{x}_T\)会只保留纯噪声部分。</p> <h1 id="reverse-process">Reverse Process</h1> <p>在前向扩散过程中，实现了：<br/> \(\mathbf{x}_0\sim p_\mathrm{complex}\rightarrow \mathbf{x}_1\rightarrow \cdots \mathbf{x}_t\rightarrow\cdots\rightarrow \mathbf{x}_T\sim p_\mathrm{prior}\)<br/> 如果能够实现将前向扩散过程反转，也就实现了从简单分布到复杂分布的映射。逆向扩散过程则是将前向过程反转，实现从简单分布随机采样样本，迭代地使用\(q(\mathbf{x}_{t-1}\vert\mathbf{x}_t)\)，最终生成复杂分布的样本，即：<br/> \(\mathbf{x}_T\sim p_\mathrm{prior}\rightarrow \mathbf{x}_{T-1}\rightarrow \cdots \mathbf{x}_t\rightarrow\cdots\rightarrow \mathbf{x}_0\sim p_\mathrm{complex}\)<br/> 为了求取\(q(\mathbf{x}_{t-1}\vert\mathbf{x}_t)\)，使用贝叶斯公式：<br/> \(\begin{align} q(\mathbf{x}_{t-1}\vert\mathbf{x}_t)&amp;=\frac{q(\mathbf{x}_t\vert\mathbf{x}_{t-1})q(\mathbf{x}_{t-1})}{q(\mathbf{x}_t)} \end{align}\)<br/> 然而，公式中\(q(x_{t-1})\)和\(q(x_t)\)不好求，根据DDPM的马尔科夫假设，可以为\(q(\mathbf{x}_{t-1}\vert\mathbf{x}_t)\)添加条件（可以证明，如果向扩散过程中的\(\beta_t\)足够小，那么\(q(\mathbf{x}_{t-1}\vert\mathbf{x}_t)\)是高斯分布。）：<br/> \(\begin{align} q(\mathbf{x}_{t-1}\vert\mathbf{x}_t)&amp;=q(\mathbf{x}_{t-1}\vert\mathbf{x}_t,\mathbf{x}_0)\\ &amp;=\frac{q(\mathbf{x}_t\vert\mathbf{x}_{t-1},\mathbf{x}_0)q(\mathbf{x}_{t-1}\vert\mathbf{x}_0)}{q(\mathbf{x}_t\vert\mathbf{x}_0)}\\ &amp;=\frac{q(\mathbf{x}_t\vert\mathbf{x}_{t-1})q(\mathbf{x}_{t-1}\vert\mathbf{x}_0)}{q(\mathbf{x}_t\vert\mathbf{x}_0)}\\ &amp;=\mathcal{N}(\mathbf{x}_{t-1};\mu(\mathbf{x}_t;\theta),\sigma_t^2\mathbf I) \end{align}\)<br/> 其中，\(\mu(x_t;\theta)\)是高斯分布的均值，\(\sigma_t\)可以用超参数表示：<br/> \(\begin{align} \mu(\mathbf{x}_t;\theta)&amp;=\frac{\sqrt{\alpha_t}(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_t}\mathbf{x}_t+ \frac{\sqrt{\bar\alpha_{t-1}}\beta_t}{1-\bar{\alpha}_t}\mathbf{x}_0\\ \sigma_t&amp;=\frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_t}\cdot\beta_t \end{align}\)<br/> 式中\(x_0\)可以反用公式\(\mathbf x_t=\sqrt{\bar{\alpha}_t}\mathbf x_0+\sqrt{1-\bar{\alpha}_t}\boldsymbol\epsilon_t\)：<br/> \(\mathbf x_0=\frac{1}{\sqrt{\bar{\alpha}_t}}\left(\mathbf{x}_t-\sqrt{1-\bar{\alpha}_t}\boldsymbol\epsilon_t\right)\)<br/> 则：<br/> \(\begin{align} \mu(\mathbf{x}_t;\theta)&amp;=\frac{\sqrt{\alpha_t}(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_t}\mathbf{x}_t+ \frac{\sqrt{\bar\alpha_{t-1}}\beta_t}{1-\bar{\alpha}_t}\mathbf{x}_0\\ &amp;=\frac{\sqrt{\alpha_t}(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_t}\mathbf{x}_t+ \frac{\sqrt{\bar\alpha_{t-1}}\beta_t}{1-\bar{\alpha}_t}\frac{1}{\sqrt{\bar{\alpha}_t}}\left(\mathbf{x}_t-\sqrt{1-\bar{\alpha}_t}\boldsymbol\epsilon_t\right)\\ &amp;=\frac{1}{\sqrt{\alpha_t}}\left(x_t-\frac{1-\alpha_t}{\sqrt{1-\bar\alpha_t}}\boldsymbol\epsilon_t\right) \end{align}\)<br/> 而在推理的时候，\(\boldsymbol\epsilon_t\)是未知的，所以使用神经网络进行预测。综上，逆向扩散过程：<br/> \(\begin{align} q(\mathbf{x}_{t-1}\vert\mathbf{x}_t)&amp;=\mathcal{N}(\mathbf{x}_{t-1};\mu(\mathbf{x}_t;\theta),\sigma_t^2\mathbf I)\\ &amp;=\mathcal{N}\left(\mathbf x_{t-1};\frac{1}{\sqrt{\alpha_t}}\left(x_t-\frac{1-\alpha_t}{\sqrt{1-\bar\alpha_t}}\boldsymbol\epsilon_\theta(\mathbf x_t, t)\right),\left(\frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_t}\cdot\beta_t\right)^2\mathbf I\right)\\ \mathbf x_{t-1}&amp;=\frac{1}{\sqrt{\alpha_t}}\left(x_t-\frac{1-\alpha_t}{\sqrt{1-\bar\alpha_t}}\boldsymbol\epsilon_\theta(\mathbf x_t, t)\right)+\frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_t}\beta_t\cdot\boldsymbol\epsilon\quad\boldsymbol\epsilon\sim\mathcal N(\mathbf 0, \mathbf I) \end{align}\)</p> <h1 id="training-object">Training Object</h1> <p>DDPM的训练目标是最小化训练数据的负对数似然：<br/> \(\begin{align} -\log p_\theta(\mathbf x_0) &amp;\le -\log p_\theta(\mathbf x_0) + \mathrm{KL}\left(q(\mathbf x_{1:T}\vert\mathbf x_0)\Vert p_\theta(\mathbf x_{1:T}\vert\mathbf x_0)\right) &amp;\ ;\mathrm{KL}(\cdot\Vert\cdot)\ge 0\\ &amp;=-\log p_\theta(\mathbf x_0)+\mathbb{E}_{\mathbf x_{1:T}\sim q(\mathbf x_{1:T}\vert\mathbf x_0)}\left[\log\frac{q(\mathbf x_{1:T}\vert\mathbf x_0)}{p_\theta(\mathbf x_{0:T})/p_\theta(\mathbf x_0)}\right]&amp;\ ;p_\theta(\mathbf x_{1:T}\vert\mathbf x_0)=\frac{p_\theta(\mathbf x_{0:T})}{p_\theta(\mathbf x_0)}\\ &amp;=-\log p_\theta(\mathbf x_0)+\mathbb{E}_{\mathbf x_{1:T}\sim q(\mathbf x_{1:T}\vert\mathbf x_0)}\left[\log\frac{q(\mathbf x_{1:T}\vert\mathbf x_0)}{p_\theta(\mathbf x_{0:T})}+\log p_\theta(\mathbf x_0)\right]\\ &amp;=\mathbb{E}_{\mathbf x_{1:T}\sim q(\mathbf x_{1:T}\vert\mathbf x_0)}\left[\log\frac{q(\mathbf x_{1:T}\vert\mathbf x_0)}{p_\theta(\mathbf x_{0:T})}\right]\\ \end{align}\)<br/> 其中\(p_\theta(\mathbf x_{1:T}\vert\mathbf x_0)\)是使用网络估计分布\(q\)（变分推断），定义\(\mathcal{L}_{\mathrm{VLB}}\triangleq\mathbb{E}_q(\mathbf x_{0:T})\left[\log\frac{q(\mathbf x_{1:T}\vert\mathbf x_0)}{p_\theta(\mathbf x_{0:T})}\right]\ge-\mathbb{E}_{q(\mathbf x_0)}\log p_\theta(\mathbf x_0)\)，那么VLB是训练数据的负对数似然的上节，最小化VLB就是最小化负对数似然。继续对VLB拆分：<br/> \(\begin{align} \mathcal{L}_{\mathrm{VLB}}&amp;=\mathbb{E}_{q(\mathbf x_{0:T})}\left[\log\frac{q(\mathbf x_{1:T}\vert\mathbf x_0)}{p_\theta(\mathbf x_{0:T})}\right]\\ &amp;=\mathbb{E}_q\left[\log\frac{\prod_{t=1}^{T}q(\mathbf x_t\vert\mathbf x_{t-1})}{p_\theta(\mathbf x_T)\prod_{t=1}^{T}p_\theta(\mathbf x_{t-1}\vert\mathbf x_t)}\right]\\ &amp;=\mathbb{E}_q\left[-\log p_\theta(\mathbf x_T)+\sum\limits^{T}_{t=1}\log\frac{q(\mathbf x_t\vert\mathbf x_{t-1})}{p_\theta(\mathbf x_{t-1}\vert\mathbf x_t)}\right]\\ &amp;=\mathbb{E}_q\left[-\log p_\theta(\mathbf x_T)+\sum\limits^{T}_{t=2}\log\frac{q(\mathbf x_t\vert\mathbf x_{t-1})}{p_\theta(\mathbf x_{t-1}\vert\mathbf x_t)}+\log\frac{q(\mathbf x_1\vert\mathbf x_0)}{p_\theta(\mathbf x_0\vert\mathbf x_1)}\right]\\ &amp;=\mathbb{E}_q\left[-\log p_\theta(\mathbf x_T)+\sum\limits^{T}_{t=2}\log\frac{q(\mathbf x_t\vert\mathbf x_{t-1}, \mathbf x_0)}{p_\theta(\mathbf x_{t-1}\vert\mathbf x_t)}+\log\frac{q(\mathbf x_1\vert\mathbf x_0)}{p_\theta(\mathbf x_0\vert\mathbf x_1)}\right] &amp;\ ;q(\mathbf x_t\vert\mathbf x_{t-1})=q(\mathbf x_t\vert\mathbf x_{t-1}, \mathbf x_0)\\ &amp;=\mathbb{E}_q\left[-\log p_\theta(\mathbf x_T)+\sum\limits^{T}_{t=2}\log\left(\frac{q(\mathbf x_{t-1}\vert\mathbf x_{t}, \mathbf x_0)}{p_\theta(\mathbf x_{t-1}\vert\mathbf x_t)} \frac{q(\mathbf x_t\vert\mathbf x_0)}{q(\mathbf x_{t-1}\vert\mathbf x_0)}\right)+\log\frac{q(\mathbf x_1\vert\mathbf x_0)}{p_\theta(\mathbf x_0\vert\mathbf x_1)}\right] &amp;\ ;\text{Bayes Theorem}\\ &amp;=\mathbb{E}_q\left[\log\frac{q(\mathbf x_T\vert\mathbf x_0)}{p_\theta(\mathbf x_T)}+\sum_{t=2}^{T}\log\frac{q(\mathbf x_{t-1}\vert\mathbf x_t, \mathbf x_0)}{p_\theta(\mathbf x_{t-1}\vert\mathbf x_t)}-\log p_\theta(\mathbf x_0\vert\mathbf x_1)\right]\\ &amp;=\mathbb{E}_q\left[\underbrace{\mathrm{KL}(q(\mathbf x_T\vert\mathbf x_0) \Vert p_\theta(\mathbf x_T))}_{\mathcal{L}_T} + \sum_{t=2}^{T}\underbrace{\mathrm{KL}(q(\mathbf x_{t-1}\vert\mathbf x_t, \mathbf x_0) \Vert p_\theta(\mathbf x_{t-1}\vert\mathbf x_t))}_{\mathcal{L}_{t-1}}-\underbrace{\log p_\theta(\mathbf x_0\vert\mathbf x_1)}_{\mathcal{L}_0}\right]\\ &amp;=\mathbb{E}_q\left[\mathcal{L}_T+\sum_{t=2}^{T}\mathcal{L}_{t-1}-\mathcal{L}_0\right] \end{align}\)</p> <ol> <li>由于\(\mathbf x_T\)是纯噪声，所以\(\mathcal{L}_T\)是常数</li> <li>对于\(\mathcal{L}_0\)，DDPM专门设计了特殊的\(p_\theta(\mathbf x_0\vert\mathbf x_1)\)</li> <li>对于\(\mathcal{L}_t\triangleq\mathrm{KL}(q(\mathbf x_t\vert\mathbf x_{t+1}, \mathbf x_0) \Vert p_\theta(\mathbf x_t \vert \mathbf x_{t+1})) \quad 1\le t \le T-1\)，是两个正态分布的KL散度，有解析解。在DDPM中，使用了简化之后的损失函数：<br/> \(\begin{align} \mathcal{L}_t^{\mathrm{simple}}&amp;=\mathbb{E}_{t\sim[1,T],\mathbf x_0,\boldsymbol\epsilon_t}\left[\Vert\boldsymbol\epsilon_t-\boldsymbol\epsilon_\theta(\sqrt{\bar{\alpha}_t}\mathbf x_0+\sqrt{1-\bar{\alpha}_t}\boldsymbol\epsilon_t,t)\Vert^2_2\right] \end{align}\) <h1 id="summary">Summary</h1> <p>综上，DDPM的训练和采样/推理过程如下图所示：</p> </li> </ol> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Pasted%20image%2020231002142935-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Pasted%20image%2020231002142935-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Pasted%20image%2020231002142935-1400.webp"/> <img src="/assets/img/Pasted%20image%2020231002142935.png" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h1 id="reference">Reference</h1> <ol> <li><a href="https://www.bilibili.com/video/BV13P411J7dm">从零开始了解Diffusion Models</a></li> <li><a href="https://ayandas.me/blog-tut/2021/12/04/diffusion-prob-models.html">https://ayandas.me/blog-tut/2021/12/04/diffusion-prob-models.html</a></li> <li><a href="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/">What are Diffusion Models</a></li> <li><a href="https://yang-song.net/blog/2021/score/">An introduction to Diffusion Probabilistic Models</a></li> </ol>]]></content><author><name>Wei Deng</name></author><category term="diffusion-model"/><summary type="html"><![CDATA[introduction about DDPM]]></summary></entry><entry><title type="html">Diffusion Models - Score-based Generative Models</title><link href="https://dw-dengwei.github.io/blog/Diffusion-Models-Score-based-Generative-Models/" rel="alternate" type="text/html" title="Diffusion Models - Score-based Generative Models"/><published>2023-10-06T00:00:00+00:00</published><updated>2023-10-06T00:00:00+00:00</updated><id>https://dw-dengwei.github.io/blog/Diffusion%20Models%20-%20Score-based%20Generative%20Models</id><content type="html" xml:base="https://dw-dengwei.github.io/blog/Diffusion-Models-Score-based-Generative-Models/"><![CDATA[<h1 id="introduction">Introduction</h1> <p>score-based生成模型是一种新的生成模型范式，在score-based之前，主要存在两种类型的生成模型：</p> <ol> <li><strong>基于似然的生成模型</strong>：基于最大似然估计（MLE），使得从真实数据分布中采样出的数据能够在所建模的数据分布中概率最大化，即\(\max_\theta \mathbb{E}_{x\sim p_\mathrm{data}(x)}\left[\log p(x;\theta)\right]\)。这类模型通过最大化似然函数，直接学习数据集的分布，主要方法有VAE、流模型、能量模型</li> <li><strong>隐式生成模型</strong>：非直接学习数据集的分布，主要方法有GAN<br/> 它们分别具有以下限制：</li> <li><strong>对于基于似然的生成模型</strong>：对神经网络的结构要求高</li> <li><strong>对于隐式生成模型</strong>：训练不稳定、容易导致模式坍塌 <h1 id="preliminary">Preliminary</h1> <p>score-based生成模型就能很好地避免这些限制，在介绍score-based生成模型之前，需要明确几个概念：</p> </li> <li><strong>能量函数</strong><br/> 对于大多数分布，可以使用概率密度函数（PDF）进行描述，也可以使用能量函数进行描述：<br/> \(p(x)=\frac{e^{-E(x)}}{Z}\)<br/> 其中\(p(x)\)是PDF，\(E(x)\)是能量函数，\(Z=\int e^{-E(x)}\mathrm{d}x\)是归一化因子。以高斯分布为例，可以使用以下能量函数进行描述：<br/> \(\begin{align} E(x;\mu,\sigma^2)&amp;=\frac{1}{2\sigma^2}(x-\mu)^2\\ p(x)&amp;=\frac{e^{-E(x)}}{\int e^{-E(x)}\mathrm dx}=\frac{e^{\frac{1}{2\sigma^2}(x-\mu)^2}}{\sqrt{2\pi\sigma^2}} \end{align}\)</li> <li><strong>能量模型</strong><br/> 能量模型是基于能量函数的生成模型：<br/> \(p_\theta(x)=\frac{\exp(-E_\theta(x))}{Z_\theta}\)<br/> 基于能量函数对数据分布进行建模的时候，<strong>如何计算能量模型的归一化函数\(Z_\theta\)是一个较难的问题</strong>。传统的基于似然的生成模型（如自回归模型、流模型、VAE）都有自己的解决方式，但是都对能量模型做了太多的约束，各自都有其限制。</li> <li><strong>蒙特卡罗采样方法：拒绝-接受法</strong><br/> 目的：希望从一个复杂分布\(p(x)\)采样\(N\)个样本<br/> 方法：使用一个简单分布\(q(x)\)为媒介（例如：高斯分布），这个分布必须满足它的\(c&gt;0\)倍大于等于\(p(x)\)。首先从简单分布\(q(x)\)中采样得到\(x^*\)，然后以\(\frac{p(x^*)}{cq(x^*)}\)的概率保留这个样本，直到得到\(N\)个样本结束。</li> </ol> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Pasted%20image%2020231002164638-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Pasted%20image%2020231002164638-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Pasted%20image%2020231002164638-1400.webp"/> <img src="/assets/img/Pasted%20image%2020231002164638.png" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <ol> <li><strong>MCMC</strong><br/> <strong>MCMC方法可以从复杂分布中进行采样</strong><br/> <strong>符号定义</strong>：\(\pi_i\triangleq\pi(i)=\lim_{t\to +\infty}P(X_t=i)\)，即马尔科夫链达到平稳分布的时候，处于第\(i\)个状态的概率。<br/> <strong>满足遍历定理的马尔可夫链</strong>：从任意起始点出发，最终都会收敛到同一个平稳分布，即殊途同归。<br/> 如果定义一个满足遍历定理的马尔可夫链，使得它的平稳分布等于目标分布\(p(x)\)，那么当经过足够长的游走时间\(m\)后，该链收敛，在之后的时间内每游走一次，就得到了服从目标分布的一个样本。该算法就被称为MCMC方法。<br/> 现在最大的问题就是：<strong>如何构造这么一个马尔可夫链，使得它的平稳分布等于目标分布？</strong><br/> TODO</li> <li><strong>基于MCMC的MLE方法</strong><br/> TODO <h1 id="how-score-based-generative-model-work">How Score-based Generative Model Work</h1> <p>对于一个基于能量函数的概率分布：<br/> \(p_\theta(x)=\frac{e^{-E_\theta(x)}}{Z_\theta}\)<br/> 对其对数似然求导：<br/> \(\begin{align} \nabla_\theta\log p_\theta(x) &amp;=\nabla_\theta\log\exp(-E_\theta(x))-\nabla_\theta\log Z_\theta\\ &amp;=-\nabla_\theta\log\exp(E_\theta(x))-\frac{1}{Z_\theta}\nabla_\theta Z_\theta &amp;\ ;\text{chain rule} \\ &amp;=-\nabla_\theta\log\exp(E_\theta(x))-\frac{1}{Z_\theta}\nabla_\theta \int\exp(-E_\theta(x))\mathrm dx &amp;\ ;\text{definition of } Z_\theta\\ &amp;=-\nabla_\theta\log\exp(E_\theta(x))+\frac{1}{Z_\theta}\int\exp(-E_\theta(x))\nabla_\theta E_\theta(x)\mathrm dx &amp;\ ;\text{chain rule}\\ &amp;=-\nabla_\theta\log\exp(E_\theta(x))+\int\frac{\exp(-E_\theta(x))}{Z_\theta}\nabla_\theta E_\theta(x)\mathrm dx\\ &amp;=-\nabla_\theta\log\exp(E_\theta(x))+\mathbb{E}_{x\sim p_\theta(x)}\left[\nabla_\theta E_\theta(x)\right] &amp;\ ;\text{definition of } p_\theta(x)\\ \end{align}\)</p> </li> </ol> <p>基于score的生成模型和扩散模型非常相似，使用了score matching和Langevin dynamics技术进行生成。其中，</p> <ol> <li>score matching是估计目标分布的概率密度的梯度 （即score，分数），记\(p(x)\)是数据分布的概率密度函数，则这个分布的score被定义为\(\nabla_x\log p(x)\)，score matching则是训练一个网络\(s_\theta\)去近似score：<br/> \(\mathcal{E}_{p(x)}\left[ \Vert\nabla_x\log p(x)-s_\theta(x)\Vert^2_2 \right]=\int p(x)\Vert\nabla_x\log p(x)-s_\theta(x)\Vert^2_2 dx\)</li> <li>Langevin dynamics是使用score采样生成数据，采样方式如下：<br/> \(x_t=x_{t-1}+\frac{\delta}{2}\nabla_x\log p(x_{t-1})+\sqrt{\delta}\epsilon, \text{ where } \epsilon\sim\mathcal{N}(0, I)\) <h1 id="reference">Reference</h1> </li> <li><a href="https://www.zhihu.com/question/499485994/answer/2552791458">能量模型能做什么，和普通的神经网络模型有什么区别，为什么要用能量模型呢？</a></li> <li><a href="https://zhuanlan.zhihu.com/p/576779879">扩散模型与能量模型，Score-Matching和SDE，ODE的关系</a></li> <li><a href="https://zhuanlan.zhihu.com/p/250146007">你一定从未看过如此通俗易懂的马尔科夫链蒙特卡罗方法(MCMC)解读(上)</a></li> <li><a href="https://arxiv.org/pdf/2101.03288.pdf">How to Train Your Energy-Based Models</a></li> </ol>]]></content><author><name>Wei Deng</name></author><category term="diffusion-model"/><summary type="html"><![CDATA[introduction about score-based generative models]]></summary></entry><entry><title type="html">PRCV2023 - AIGC Tutorial</title><link href="https://dw-dengwei.github.io/blog/PRCV2023-AIGC%E8%AE%B2%E4%B9%A0%E7%8F%AD/" rel="alternate" type="text/html" title="PRCV2023 - AIGC Tutorial"/><published>2023-10-06T00:00:00+00:00</published><updated>2023-10-06T00:00:00+00:00</updated><id>https://dw-dengwei.github.io/blog/PRCV2023%20-%20AIGC%E8%AE%B2%E4%B9%A0%E7%8F%AD</id><content type="html" xml:base="https://dw-dengwei.github.io/blog/PRCV2023-AIGC%E8%AE%B2%E4%B9%A0%E7%8F%AD/"><![CDATA[<p>1<br/> GAP-Lab<br/> 香港中文大学 韩晓光<br/> PaSS讲座</p> <h1 id="三维生成">三维生成</h1> <ul> <li>SweetDreamer</li> </ul> <p>难点：</p> <ul> <li>视频连续性</li> <li>三维生成</li> </ul> <p>怎么跟热点</p> <ul> <li>垂直领域：人脸、人体、衣服 <ul> <li>针对domain提出特定的算法，不能是general的</li> </ul> </li> <li>推广：图像到视频、二维到三维 <ul> <li>例如：nerf（possion nerf blending)</li> <li>需要广泛涉猎，想到比做到难</li> </ul> </li> <li>硬卷 <ul> <li>关键：找到问题、找到本质问题！！</li> <li>例：SD缺少同一场景多视角分布/几何与材质解耦/缺少数据</li> </ul> </li> </ul> <p>怎么不用跟着卷</p> <ul> <li>挖坑：衣服、卡通（有没有人follow、资金）</li> <li> <p>想本质问题：MVImgNet（三维ImageNet数据集）</p> </li> <li>SD finetune</li> <li>SD loss</li> <li>SD 生成数据</li> </ul> <h2 id="2">2</h2> <p>ARC Tencent</p> <h1 id="精细控制">精细控制</h1> <ul> <li>T2I-Adapter</li> <li>CoAdapter：组合控制</li> <li>MasaCtrl：更一致的生成与编辑 <ul> <li>Unet Decoder</li> </ul> </li> </ul> <h1 id="交互方式">交互方式</h1> <ul> <li>使用LLM生成指令：LLMDiffusion</li> </ul>]]></content><author><name>Wei Deng</name></author><category term="diffusion-model"/><summary type="html"><![CDATA[PRCV2023 AIGC Tutorial]]></summary></entry><entry><title type="html">Diffusion Models - 3D Generation</title><link href="https://dw-dengwei.github.io/blog/Diffusion-Models-3D-Generation/" rel="alternate" type="text/html" title="Diffusion Models - 3D Generation"/><published>2023-10-06T00:00:00+00:00</published><updated>2023-10-06T00:00:00+00:00</updated><id>https://dw-dengwei.github.io/blog/Diffusion%20Models%20-%203D%20Generation</id><content type="html" xml:base="https://dw-dengwei.github.io/blog/Diffusion-Models-3D-Generation/"><![CDATA[<h1 id="22-10-06_watson_novel-view-synthesis-with-diffusion-models">22-10-06_Watson_Novel View Synthesis with Diffusion Models</h1> <p>Google Research作品</p> <ul> <li>将输入图片旋转到指定视角</li> </ul> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Pasted%20image%2020231029160243-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Pasted%20image%2020231029160243-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Pasted%20image%2020231029160243-1400.webp"/> <img src="/assets/img/Pasted%20image%2020231029160243.png" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <ul> <li>pose-conditional image-to-image diffusion model</li> </ul> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Pasted%20image%2020231029160258-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Pasted%20image%2020231029160258-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Pasted%20image%2020231029160258-1400.webp"/> <img src="/assets/img/Pasted%20image%2020231029160258.png" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <ul> <li>使用stochastic conditioning鼓励扩散模型生成3D一致的样本</li> </ul> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Pasted%20image%2020231029164722-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Pasted%20image%2020231029164722-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Pasted%20image%2020231029164722-1400.webp"/> <img src="/assets/img/Pasted%20image%2020231029164722.png" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>自回归地生成新视角，conditioning set表示已经有的视角，最开始只有输入图片，随着不断地生成新视角图片，conditioning set逐渐扩增。其中，采样过程中，每一次denoising step都会更换image condition（从conditioning set中随机抽取）</p> <ul> <li>针对该任务对UNet结构重新设计<br/> 使用concat的方法将conditioning image融合进模型，效果不好，作者的猜测：只使用self-attention难以学到视角的变换。对于结构的改进见论文，也许后续的文章不再使用这个结构。</li> <li>提出geometry-free新视角生成模型的metric：3D consistency scoring<br/> 现有的评价方法无法正确地对三位一致性进行评判，于是提出3D consistency scoring，满足如下要求： <ol> <li>对不满足3D一致性的输出进行惩罚</li> <li><strong>不</strong>对满足3D一致性但是和GT有出入的输出进行惩罚</li> <li>对不符合输入图片的输出进行惩罚<br/> 使用NeRF重建多个新视角图片，具体见原论文<br/> 总结：使用pose-guided diffusion model生成新视角，在采样的时候对之前生成的图片都进行考虑，以达到3D一致性</li> </ol> </li> </ul> <h1 id="22-12-06_deng_nerdi-single-view-nerf-synthesis-with-language-guided-diffusion-as-general-image-priors">22-12-06_Deng_NeRDi: Single-View NeRF Synthesis with Language-Guided Diffusion as General Image Priors</h1> <p>使用SDS优化NeRF有一个问题，预训练模型提供给NeRF的先验不够specific，所以生成出来的三维模型比较平滑，趋向与生成一个比较“平均”的模型</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Pasted%20image%2020231030002657-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Pasted%20image%2020231030002657-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Pasted%20image%2020231030002657-1400.webp"/> <img src="/assets/img/Pasted%20image%2020231030002657.png" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>所以本文将预训练扩散模型提供的先验分布“缩小”。使用到的扩散模型是text-to-image扩散模型，输入的condition是caption以及使用textual inversion获得的与图片对齐的文本编码。<br/> NeRF除了使用SDS进行优化以外，还使用GT单视角图片进行监督。相当于NeRF看到的是输入的单视角图片+先验分布被缩小的扩散模型</p> <h1 id="23-02-15_zhou_sparsefusion-distilling-view-conditioned-diffusion-for-3d-reconstruction">23-02-15_Zhou_SparseFusion: Distilling View-conditioned Diffusion for 3D Reconstruction</h1> <p>少视角NeRF重建<br/> 相对于DreamFusion，主要的创新是训练了一个新的扩散模型VLDM</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Pasted%20image%2020231029205551-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Pasted%20image%2020231029205551-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Pasted%20image%2020231029205551-1400.webp"/> <img src="/assets/img/Pasted%20image%2020231029205551.png" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>输入少量视角的图片、对应的相机参数以及目标相机参数，使用EFT将所有condition编码起来</p> <h1 id="23-02-20_gu_nerfdiff-single-image-view-synthesis-with-nerf-guided-distillation-from-3d-aware-diffusion">23-02-20_Gu_NerfDiff: Single-image View Synthesis with NeRF-guided Distillation from 3D-aware Diffusion</h1> <p>依然是训练一个新的view+image conditioned 扩散模型</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Pasted%20image%2020231029211217-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Pasted%20image%2020231029211217-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Pasted%20image%2020231029211217-1400.webp"/> <img src="/assets/img/Pasted%20image%2020231029211217.png" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>使用UNet对图像进行翻译，转化为三平面，然后在目标视角下采样作为CDM的condition image。两个UNet同时训练：去噪loss+重建loss<br/> 扩散模型中用到的Image-conditioned NeRF可以输入图片和相机视角，输出对应视角的图片，但是目前输出的新视角质量较差，于是使用训练完成的扩散模型对这个NeRF进行微调。<br/> 有点左脚踩右脚升天的感觉，但是论文效果不错</p> <h1 id="23-03-17_lei_rgbd2-generative-scene-synthesis-via-incremental-view-inpainting-using-rgbd-diffusion-models">23-03-17_Lei_RGBD2: Generative Scene Synthesis via Incremental View Inpainting using RGBD Diffusion Models</h1> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Pasted%20image%2020231029214114-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Pasted%20image%2020231029214114-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Pasted%20image%2020231029214114-1400.webp"/> <img src="/assets/img/Pasted%20image%2020231029214114.png" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>输入RGB-D序列（只有少量视角），输出对整个场景重建的mesh<br/> 核心思想是利用扩散模型对场景中的孔洞进行补全</p> <h1 id="23-03-20_liu_zero-1-to-3-zero-shot-one-image-to-3d-object">23-03-20_Liu_Zero-1-to-3: Zero-shot One Image to 3D Object</h1> <p>输入图片和目标相机视角，输出符合图片和相机视角的图片，然后可以用这个预训练模型结合SJC生成3D模型<br/> 这篇文章相比之前的文章来说，贡献之一是证明了大规模预训练扩散模型有潜力理解图像的三维结构，那么使用in-the-wild 图片也能很好地进行三维重建</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Pasted%20image%2020231029151838-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Pasted%20image%2020231029151838-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Pasted%20image%2020231029151838-1400.webp"/> <img src="/assets/img/Pasted%20image%2020231029151838.png" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h1 id="23-03-30_tseng_consistent-view-synthesis-with-pose-guided-diffusion-models">23-03-30_Tseng_Consistent View Synthesis with Pose-Guided Diffusion Models</h1> <p>同样是训练一个pose-guided diffusion model，输入图片和目标相机参数，输出对应图片。<br/> 本文的创新在于提出了一种让UNet理解相机参数的机制，具体来说，提出了一种名为极线注意力机制，利用相机内外参得到的极线约束，对Cross attention产生的注意力分数矩阵进行修改，从而提供让网络能够理解相机视角<br/> 文中还交代了一些提高三维一致性的trick</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Pasted%20image%2020231030011953-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Pasted%20image%2020231030011953-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Pasted%20image%2020231030011953-1400.webp"/> <img src="/assets/img/Pasted%20image%2020231030011953.png" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h1 id="23-03-31_xiang_3d-aware-image-generation-using-2d-diffusion-models">23-03-31_Xiang_3D-aware Image Generation using 2D Diffusion Models</h1> <p>和RGBD2 (Lei et. al.) 的方法类似，使用扩散模型预测RGBD，然后手动旋转，将产生的孔洞用扩散模型补全，循环<br/> 图形学设计较多</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Pasted%20image%2020231030012551-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Pasted%20image%2020231030012551-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Pasted%20image%2020231030012551-1400.webp"/> <img src="/assets/img/Pasted%20image%2020231030012551.png" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h1 id="23-04-05_chan_generative-novel-view-synthesis-with-3d-aware-diffusion-models">23-04-05_Chan_Generative Novel View Synthesis with 3D-Aware Diffusion Models</h1> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Pasted%20image%2020231118183023-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Pasted%20image%2020231118183023-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Pasted%20image%2020231118183023-1400.webp"/> <img src="/assets/img/Pasted%20image%2020231118183023.png" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>和其它的新视角生成模型相比，不同的就是condition的方式<br/> zero123是将相机参数融合到图像的CLIP embedding里<br/> 这个方法是引入了nerf，首先将一个或多个视角的图片编码得到nerf表示，然后进行体渲染得到目标视角的feature作为condition<br/> 为什么要引入nerf？TODO</p> <h1 id="23-06-16_dreamsparse-escaping-from-platos-cave-with-2d-frozen-diffusion-model-given-sparse-views">23-06-16_DreamSparse: Escaping from Plato’s Cave with 2D Frozen Diffusion Model Given Sparse Views</h1> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Pasted%20image%2020231118193101-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Pasted%20image%2020231118193101-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Pasted%20image%2020231118193101-1400.webp"/> <img src="/assets/img/Pasted%20image%2020231118193101.png" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>又提供了一种将目标视角作为condition的方法，目前看不懂</p> <h1 id="23-06-29_one-2-3-45-any-single-image-to-3d-mesh-in-45-seconds-without-per-shape-optimization">23-06-29_One-2-3-45: Any Single Image to 3D Mesh in 45 Seconds without Per-Shape Optimization</h1> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Pasted%20image%2020231118195042-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Pasted%20image%2020231118195042-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Pasted%20image%2020231118195042-1400.webp"/> <img src="/assets/img/Pasted%20image%2020231118195042.png" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>直接使用Zero123生成的多视角图片进行NeRF重建效果不好，是因为Zero123生成的图片具有多视角不一致性<br/> 本方法使用Zero123生成的有缺陷的图片作为SparseNeuS的输入进行重建<br/> 这个方法没有重新训练或微调一个扩散模型，而是利用了现有的Zero123进行多视角图片的生成3D模型，并且不是基于SDS那样的优化方法，生成速度更快</p>]]></content><author><name>Wei Deng</name></author><category term="diffusion-model"/><category term="3d-generation"/><summary type="html"><![CDATA[3D generation diffusion model papers]]></summary></entry><entry><title type="html">Generative Models - GANs v.s. VAEs v.s. Diffusion Models</title><link href="https://dw-dengwei.github.io/blog/Generative-Models-GANs-v.s.-VAEs-v.s.-Diffusion-Models/" rel="alternate" type="text/html" title="Generative Models - GANs v.s. VAEs v.s. Diffusion Models"/><published>2023-10-06T00:00:00+00:00</published><updated>2023-10-06T00:00:00+00:00</updated><id>https://dw-dengwei.github.io/blog/Generative%20Models%20-%20GANs%20v.s.%20VAEs%20v.s.%20Diffusion%20Models</id><content type="html" xml:base="https://dw-dengwei.github.io/blog/Generative-Models-GANs-v.s.-VAEs-v.s.-Diffusion-Models/"><![CDATA[<blockquote> <h2 id="from-httpspubtowardsainetdiffusion-models-vs-gans-vs-vaes-comparison-of-deep-generative-models-67ab93e0d9ae">From: https://pub.towardsai.net/diffusion-models-vs-gans-vs-vaes-comparison-of-deep-generative-models-67ab93e0d9ae</h2> <h1 id="gans">GANs</h1> <ul> <li>GAN = Generator + Discriminator</li> <li>Training loss: adversarial loss. The generator aims to “fool” a discriminator.</li> <li>High-fidelity results. The discriminator cannot distinguish between the fake and real samples.</li> <li>Low-diversity results (mode collapse): When the discriminator has over-trained or catastrophic forgetting happens, the generator might be happy enough to produce a small part of data diversity.</li> <li>Hard to train. It can difficult to determine when your network converged.</li> </ul> </blockquote> <h1 id="vaes">VAEs</h1> <ul> <li>VAE = Encoder + Decoder</li> <li>Training by maximizing log-likelihood.</li> </ul> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Pasted%20image%2020231029144619-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Pasted%20image%2020231029144619-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Pasted%20image%2020231029144619-1400.webp"/> <img src="/assets/img/Pasted%20image%2020231029144619.png" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure>]]></content><author><name>Wei Deng</name></author><category term="generative-models"/><summary type="html"><![CDATA[comparision of GANs, VAEs and Diffusion Models]]></summary></entry><entry><title type="html">Valse 20211201 Panel</title><link href="https://dw-dengwei.github.io/blog/Valse-Panel/" rel="alternate" type="text/html" title="Valse 20211201 Panel"/><published>2023-10-06T00:00:00+00:00</published><updated>2023-10-06T00:00:00+00:00</updated><id>https://dw-dengwei.github.io/blog/Valse%20Panel</id><content type="html" xml:base="https://dw-dengwei.github.io/blog/Valse-Panel/"><![CDATA[<p>https://www.bilibili.com/video/BV1pL4y1W7pT</p> <hr/> <h1 id="做科研需要培养的能力或习惯是什么">做科研需要培养的能力或习惯是什么？</h1> <blockquote> <p>山世光：</p> <ol> <li>摒弃被动学习的习惯，以创造新知识为目标</li> <li><strong>养成按照科学逻辑工作的习惯</strong> <ol> <li>从问题出发，调研，提出问题，动机，设计思路，实验验证，循环</li> </ol> </li> <li>养成将问题形式化的习惯 <ol> <li>沟通的时候使用语言描述问题有歧义性，最好形式化（严谨、清晰）</li> </ol> </li> <li>提升科学审美能力 <ol> <li>如何评价不同工作的价值</li> <li>这个能力反映了自己做研究的时候做什么样的研究</li> <li>构建一个领域的知识树，工作是在这个知识树上的哪个位置<br/> 黄高：</li> </ol> </li> <li>时间管理的习惯 <ol> <li>防止时间被碎片化</li> <li>一段集中的时间专心做事（半个小时、一个小时）</li> <li>规律作息</li> </ol> </li> <li>强烈的好奇心</li> <li>走出舒适区</li> <li>找到一个方向就专注<br/> 潘玲</li> <li>心态的调整能力</li> <li>不要太关注于其他人的进展，不要让自己的节奏被打乱 <h1 id="如何找到自己的研究方向">如何找到自己的研究方向</h1> <p>山世光：</p> </li> <li>兴趣？梦想？对未来的判断？</li> <li>听导师的<br/> 黄高：</li> <li><strong>问自己几个问题</strong> <ol> <li>是不是有实际价值？有实际价值才有生命力。</li> <li>选的这个题目，为什么三五年前别人做不了？ <ol> <li>如果三五年前已经有人在想这个问题了，那么别人没有做出来，自己做出来的概率可能也比较小</li> </ol> </li> <li>自己（本课题组）做有什么优势（对自己有认识） <ol> <li>自己/组里有前期积累？</li> <li>擅长数学？</li> <li>编程厉害？</li> <li>对于这个题目组里有良好的讨论氛围？</li> <li>……</li> </ol> </li> </ol> </li> <li>和导师沟通<br/> 闫杰熹：</li> <li>多看文章</li> <li>抓热点 <h1 id="如何找到好的idea">如何找到“好的”Idea</h1> <p>游凯超</p> </li> <li>现有的论文，解决了什么问题，有什么不足</li> <li>多人一起讨论，避免自己陷入局部最优<br/> 闫杰熹</li> <li>多交流，也可以和不同领域的人一起讨论<br/> 潘玲</li> <li>在网上关注学术动态（微信公众号，Twitter）<br/> 袁粒</li> <li><strong>自己动手实践、复现重要的、新的工作，在动手的时候发现问题，复现的时候分析</strong></li> <li>如果是拍脑袋尝试idea，试错成本较高</li> <li>跨学科交流<br/> 黄高（DenseNet的Idea是怎么产生的？）</li> <li>神经网络是一个复合函数</li> <li>如果从浅层直接连到output，那么相当于这个函数只复合了很少的次数，比较光滑 <h1 id="科研期间遇到了什么挑战如何克服的如何在科研不顺论文被拒的时候调整心态">科研期间遇到了什么挑战、如何克服的？如何在科研不顺、论文被拒的时候调整心态</h1> <p>袁粒</p> </li> <li>要认识到，无论是大佬还是科研小白，拒稿都是经常发生的事情</li> <li>认真地按照审稿意见修改<br/> 闫杰熹</li> <li>多沟通，避免自我否定，从师兄师姐、导师那里寻求帮助<br/> 潘玲</li> <li>不要以投稿的结果来评判自己的工作 <ol> <li>我的paper被拒了是不是这个工作真的就这么糟糕？No！<br/> 山世光</li> </ol> </li> <li>遇到觉得审稿人没怎么看自己的文章 <ol> <li>反思自己是不是没写好文章，没表述清楚（90%+都是这种情况）</li> <li>怎么表达清楚？即使是“不懂”的人，都能看到这篇文章的价值 <h1 id="如何与导师同学沟通合作">如何与导师、同学沟通、合作</h1> <p>游凯超</p> </li> </ol> </li> <li>导师有不同风格，要适应 <ol> <li>push型（有压迫感，但是长进快）</li> <li>佛型（有自己的空间，但是需要自己利用这些空间去找方向）</li> <li>只管大方向，不管小方向（一般大方向把握得都挺好）</li> </ol> </li> <li>导师都喜欢积极主动，而不是等着导师来叫你干嘛干嘛 <ol> <li>博士生到底是不是学生？不是！</li> <li>学生和导师是一个共同进步、共同探索未知的合作关系</li> <li>自己要有自信是自己那个小方向最懂的那个人之一<br/> 山世光</li> </ol> </li> <li>也不要假设导师什么都懂 <ol> <li>不一定明白背景</li> </ol> </li> <li>多找导师讨论</li> <li>不要把所有事情丢给导师</li> </ol> </blockquote>]]></content><author><name>Wei Deng</name></author><category term="valse"/><summary type="html"><![CDATA[valse panel]]></summary></entry></feed>